{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ETL Pipeline for PySpark ML**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn the complete ETL pipeline and how it is used for data analysis using ML. We would be going through the below steps :\n",
    "##### * Extract files from various formats/sources\n",
    "##### * Transform the files\n",
    "##### *  Load the files into AWS RDS MySQL\n",
    "##### *  Import the Spark ML and Statistics Libraries\n",
    "##### *  Read the data from database into data frame and then into RDD\n",
    "##### *  Perform basic SQL and statistics operations using Spark\n",
    "##### *  Build a simple linear regression model using Spark ML\n",
    "##### *  Train the model and perform evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas is a popular data science package for Python. We use Pandas here to read the files from the disc which are in different formats (csv,json,xml) and convert it into a pandas dataframe. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as ET  # this module helps in processing XML files.\n",
    "#from sqlalchemy import create_engine\n",
    "#!pip install PyMySQL\n",
    "#import pymysql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ETL\n",
    "### The fundamental aim of ETL is to combine data from multiple data sources into a single, consistent data store. Here we are trying to extract data from files with various file formats and loading into our target system, which in our case, is the AWS RDS MySql. In the real world scenario these files may have been extracted from different sources like web scraping, database etc. \n",
    "\n",
    "### I have used cars.csv data available online at kaggle and created three different files for this purpose (csv, json, xml).The data files contain 9 different columns namely :  \"mpg\",\"cylinders\",\"displacement\",\"horsepower\",\"weight\",\"acceleration\",\"model\",\"origin\",\"car_name\"\n",
    "\n",
    "### Once we have our data loaded into the database, our final objective would be to predict the mpg based on the horsepower and weight of the car."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for extracting data from different file formats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_from_csv(file_to_process):\n",
    "    dataframe = pd.read_csv(file_to_process)\n",
    "    return dataframe\n",
    "\n",
    "def extract_data_from_json(file_to_process):\n",
    "    dataframe = pd.read_json(file_to_process, orient = 'records', lines=True)\n",
    "    return dataframe\n",
    "\n",
    "def extract_data_from_xml(file_to_process):\n",
    "    dataframe = pd.DataFrame(columns=[\"mpg\",\"cylinders\",\"displacement\",\"horsepower\",\"weight\",\"acceleration\",\"model\",\"origin\",\"car_name\"])\n",
    "    tree = ET.parse(file_to_process)\n",
    "    root = tree.getroot()\n",
    "    for person in root:\n",
    "        if person.find(\"horsepower\").text:\n",
    "            mpg = float(person.find(\"mpg\").text)\n",
    "            cylinders = float(person.find(\"cylinders\").text)\n",
    "            displacement = float(person.find(\"displacement\").text)\n",
    "            horsepower = float(person.find(\"horsepower\").text)\n",
    "            weight = float(person.find(\"weight\").text)\n",
    "            acceleration = float(person.find(\"acceleration\").text)\n",
    "            model = float(person.find(\"model\").text)\n",
    "            origin = float(person.find(\"origin\").text)\n",
    "            car_name = person.find(\"car_name\").text\n",
    "            dataframe = dataframe.append({\"mpg\":mpg,\"cylinders\":cylinders,\"displacement\":displacement,\"horsepower\":horsepower,\"weight\":weight,\"acceleration\":acceleration,\"model\":model,\"origin\":origin,\"car_name\":car_name}, ignore_index=True)\n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The different format files are stored in staging_are directory. The function extract_data reads the files and returns a consolidated dataframe. \n",
    "### Ideally the files may be stored in the staging area with new folder every day with the corresponding date. So your ETL pipeline may be scheduled to be triggered at some time of the day, which will pick all the files in the folders corresponding to the current date and do the processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_data():\n",
    "    extracted_data = pd.DataFrame(columns=[\"mpg\",\"cylinders\",\"displacement\",\"horsepower\",\"weight\",\"acceleration\",\"model\",\"origin\",\"car_name\"]) # create an empty data frame to hold extracted data\n",
    "    \n",
    "    #process all csv files\n",
    "    extracted_data = extracted_data.append(extract_data_from_csv(\"staging_area/cars123.csv\"),ignore_index=True)\n",
    "\n",
    "    #process all json files\n",
    "    extracted_data = extracted_data.append(extract_data_from_json(\"staging_area/cars123.json\"),ignore_index=True)\n",
    "\n",
    "    #process all xml files\n",
    "    extracted_data = extracted_data.append(extract_data_from_xml(\"staging_area/cars123.xml\"),ignore_index=True)\n",
    "    extracted_data.drop(['columns','index','data'], axis=1, inplace=True)\n",
    "\n",
    "    return extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_df = extract_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mpg             260\n",
      "cylinders       260\n",
      "displacement    260\n",
      "horsepower      258\n",
      "weight          260\n",
      "acceleration    260\n",
      "model           260\n",
      "origin          260\n",
      "car_name        260\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(extracted_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model</th>\n",
       "      <th>origin</th>\n",
       "      <th>car_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick skylark 320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc rebel sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford torino</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  mpg cylinders  displacement  horsepower weight  acceleration model origin  \\\n",
       "0  18         8         307.0       130.0   3504          12.0    70      1   \n",
       "1  15         8         350.0       165.0   3693          11.5    70      1   \n",
       "2  18         8         318.0       150.0   3436          11.0    70      1   \n",
       "3  16         8         304.0       150.0   3433          12.0    70      1   \n",
       "4  17         8         302.0       140.0   3449          10.5    70      1   \n",
       "\n",
       "                    car_name  \n",
       "0  chevrolet chevelle malibu  \n",
       "1          buick skylark 320  \n",
       "2         plymouth satellite  \n",
       "3              amc rebel sst  \n",
       "4                ford torino  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 261 entries, 0 to 260\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   mpg           260 non-null    object \n",
      " 1   cylinders     260 non-null    object \n",
      " 2   displacement  260 non-null    float64\n",
      " 3   horsepower    258 non-null    float64\n",
      " 4   weight        260 non-null    object \n",
      " 5   acceleration  260 non-null    float64\n",
      " 6   model         260 non-null    object \n",
      " 7   origin        260 non-null    object \n",
      " 8   car_name      260 non-null    object \n",
      "dtypes: float64(3), object(6)\n",
      "memory usage: 18.5+ KB\n"
     ]
    }
   ],
   "source": [
    "extracted_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are interested in the three columns only i.e. 'mpg','horsepower' and 'weight' for predictions and hence transforming only these columns. Ideally you would want to update null values with mean or std but for this data we are good removing the row containg null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(extracted_df):\n",
    "    if extracted_df['horsepower'].isna().sum() > 0:\n",
    "        extracted_df = extracted_df.dropna(subset=['horsepower'])\n",
    "    if extracted_df['mpg'].isna().sum() > 0:\n",
    "        extracted_df = extracted_df.dropna(subset=['mpg'])\n",
    "    if extracted_df['weight'].isna().sum() > 0:\n",
    "        extracted_df = extracted_df.dropna(subset=['weight'])\n",
    "    #transform these 3 columns into numeric\n",
    "    extracted_df[['mpg', 'horsepower','weight']] = extracted_df[['mpg', 'horsepower','weight' ]].apply(pd.to_numeric)\n",
    "    return extracted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_transformed_df = transform_data(extracted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 258 entries, 0 to 260\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   mpg           258 non-null    float64\n",
      " 1   cylinders     258 non-null    object \n",
      " 2   displacement  258 non-null    float64\n",
      " 3   horsepower    258 non-null    float64\n",
      " 4   weight        258 non-null    int64  \n",
      " 5   acceleration  258 non-null    float64\n",
      " 6   model         258 non-null    object \n",
      " 7   origin        258 non-null    object \n",
      " 8   car_name      258 non-null    object \n",
      "dtypes: float64(4), int64(1), object(4)\n",
      "memory usage: 20.2+ KB\n"
     ]
    }
   ],
   "source": [
    "extracted_transformed_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQLAlchemy is the Python SQL toolkit and Object Relational Mapper that gives application developers the full power and flexibility of SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyMySQL in c:\\users\\zz02m9744\\anaconda3\\lib\\site-packages (1.0.2)\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "!pip install PyMySQL\n",
    "import pymysql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python functions using sqlalchemy to make a connection, close a connection and load data into the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_dbms():\n",
    "    try:\n",
    "        engine = create_engine(\"mysql+pymysql://admin:awsmysql123@carsdata.cn7zucr0kgac.us-east-1.rds.amazonaws.com:3306/carsdata\")\n",
    "        print(\"MySQL connection established\")\n",
    "    except Error as e:\n",
    "        print(\"Error while connecting to MySQL\", e)\n",
    "    return engine\n",
    "\n",
    "def close_dbms_connection(engine):\n",
    "    if engine.connect():\n",
    "        engine.connect().close()\n",
    "        print(\"MySQL connection is closed\")\n",
    "\n",
    "def load_data_into_dbms(df_to_db):\n",
    "    try:\n",
    "        engine = connect_to_dbms()\n",
    "        print(\"Loading data into MySQL database\")\n",
    "        df_to_db.to_sql('carsdata', con=engine, index = False,if_exists='append')\n",
    "        print(\"Loading data into MySQL database completed\")\n",
    "        \n",
    "    except Error as e:\n",
    "        print(\"Error while connecting to MySQL\", e)\n",
    "        \n",
    "    finally:\n",
    "        close_dbms_connection(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySQL connection established\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Engine(mysql+pymysql://admin:***@carsdata.cn7zucr0kgac.us-east-1.rds.amazonaws.com:3306/carsdata)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connect_to_dbms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySQL connection established\n",
      "Loading data into MySQL database\n",
      "Loading data into MySQL database completed\n",
      "MySQL connection is closed\n"
     ]
    }
   ],
   "source": [
    "load_data_into_dbms(extracted_transformed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "load(extracted_transformed_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The complete ETL pipeline which will extract, transform and load data into the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ETL_Pipeline():\n",
    "    print(\"Extraction Started!!!!!\")\n",
    "    extracted_df = extract_data()\n",
    "    print(extracted_df.info())\n",
    "    print(\"Extraction Completed!!!!!\")\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print(\"Transformation of data started!!!!!\")\n",
    "    extracted_transformed_df = transform_data(extracted_df)\n",
    "    print(extracted_transformed_df.info())\n",
    "    print(\"Transformation of data completed!!!!!\")\n",
    "    print(\"\")\n",
    "    print(\"\")    \n",
    "    print(\"Loading of data into RDBMS started!!!!!\")\n",
    "    load_data_into_dbms(extracted_transformed_df)\n",
    "    print(\"Loading of data into RDBMS completed!!!!!\")\n",
    "    print(\"\")\n",
    "    print(\"\")    \n",
    "    return extracted_transformed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generally the extracted and transformed data can be stored into any file storage system like AWS S3 or an RDBMS for analytics and BI. Here we are storing it into database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction Started!!!!!\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 261 entries, 0 to 260\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   mpg           260 non-null    object \n",
      " 1   cylinders     260 non-null    object \n",
      " 2   displacement  260 non-null    float64\n",
      " 3   horsepower    258 non-null    float64\n",
      " 4   weight        260 non-null    object \n",
      " 5   acceleration  260 non-null    float64\n",
      " 6   model         260 non-null    object \n",
      " 7   origin        260 non-null    object \n",
      " 8   car_name      260 non-null    object \n",
      "dtypes: float64(3), object(6)\n",
      "memory usage: 18.5+ KB\n",
      "None\n",
      "Extraction Completed!!!!!\n",
      "\n",
      "\n",
      "Transformation of data started!!!!!\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 258 entries, 0 to 260\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   mpg           258 non-null    float64\n",
      " 1   cylinders     258 non-null    object \n",
      " 2   displacement  258 non-null    float64\n",
      " 3   horsepower    258 non-null    float64\n",
      " 4   weight        258 non-null    int64  \n",
      " 5   acceleration  258 non-null    float64\n",
      " 6   model         258 non-null    object \n",
      " 7   origin        258 non-null    object \n",
      " 8   car_name      258 non-null    object \n",
      "dtypes: float64(4), int64(1), object(4)\n",
      "memory usage: 20.2+ KB\n",
      "None\n",
      "Transformation of data completed!!!!!\n",
      "\n",
      "\n",
      "Loading of data into RDBMS started!!!!!\n",
      "MySQL connection established\n",
      "Loading data into MySQL database\n",
      "Loading data into MySQL database completed\n",
      "MySQL connection is closed\n",
      "Loading of data into RDBMS completed!!!!!\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 258 entries, 0 to 260\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   mpg           258 non-null    float64\n",
      " 1   cylinders     258 non-null    object \n",
      " 2   displacement  258 non-null    float64\n",
      " 3   horsepower    258 non-null    float64\n",
      " 4   weight        258 non-null    int64  \n",
      " 5   acceleration  258 non-null    float64\n",
      " 6   model         258 non-null    object \n",
      " 7   origin        258 non-null    object \n",
      " 8   car_name      258 non-null    object \n",
      "dtypes: float64(4), int64(1), object(4)\n",
      "memory usage: 20.2+ KB\n"
     ]
    }
   ],
   "source": [
    "extracted_transformed_df = ETL_Pipeline()\n",
    "extracted_transformed_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In case you have difficulty setting up AWS RDS, you can use below snippet to write to file and load back into data frame\n",
    "#store the extracted and transformed data to a csv file, then read the file back into spark data frame\n",
    "\n",
    "## Write data to file\n",
    "#extracted_transformed_df.to_csv('extracted_transformed_cars_data.csv',index=False)\n",
    "\n",
    "## Read data from file into data frame\n",
    "#ml_data = pd.read_csv('extracted_transformed_cars_data.csv',\n",
    "#                    dtype={\n",
    "#                    \"mpg\": float,\n",
    "#                    \"cylinders\": int,\n",
    "#                    \"displacement\": float,\n",
    "#                    \"horsepower\": float,\n",
    "#                    \"weight\": float,\n",
    "#                    \"acceleration\": float,\n",
    "#                    \"model\": int,\n",
    "#                    \"origin\": int,\n",
    "#                    \"car_name\": str\n",
    "#                 })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Loading data into a Spark DataFrame\n",
    "In this section, you will first read the CSV file into a pandas dataframe and then read it into a Spark dataframe\n",
    "\n",
    "Pandas is a library used for data manipulation and analysis. Pandas offers data structures and operations for creating and manipulating Data Series and DataFrame objects. Data can be imported from various data sources, e.g., Numpy arrays, Python dictionaries and CSV files. Pandas allows you to manipulate, organize and display the data.\n",
    "\n",
    "In this example we use a dataset that contains information about cars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2: Initialize Spark session\n",
    "\n",
    "To work with dataframes we just need to verify that the spark session instance has been created.\n",
    "Feel free to click on the \"Spark UI\" button to explore the Spark UI elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: pyspark\n",
      "Version: 3.1.2\n",
      "Summary: Apache Spark Python API\n",
      "Home-page: https://github.com/apache/spark/tree/master/python\n",
      "Author: Spark Developers\n",
      "Author-email: dev@spark.apache.org\n",
      "License: http://www.apache.org/licenses/LICENSE-2.0\n",
      "Location: c:\\users\\zz02m9744\\anaconda3\\lib\\site-packages\n",
      "Requires: py4j\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip3 show pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have all the requirements installed, we need to install findspark and initialize it. \n",
    "findpsark lib will locate the spark on the system and import the library for you to initalize the spark context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark==3.1.2 in c:\\users\\zz02m9744\\anaconda3\\lib\\site-packages (3.1.2)\n",
      "Requirement already satisfied: py4j==0.10.9 in c:\\users\\zz02m9744\\anaconda3\\lib\\site-packages (from pyspark==3.1.2) (0.10.9)\n",
      "Requirement already satisfied: findspark in c:\\users\\zz02m9744\\anaconda3\\lib\\site-packages (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pyspark==3.1.2\n",
    "!pip install findspark\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pyspark is the Spark API for Python. Here we use pyspark to initialize the spark context. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets create the spark session and context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a spark context class\n",
    "sc = SparkContext()\n",
    "\n",
    "# Creating a spark session\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"ETL for Python Spark ML DataFrames\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To work with dataframes we just need to verify that the spark session instance has been created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://WIN-O6G9L60IV0B:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x18668738550>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySQL connection established\n"
     ]
    }
   ],
   "source": [
    "engine = connect_to_dbms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data = pd.read_sql(\"select * from carsdata\", engine);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We use the `createDataFrame` function to load the data into a spark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = spark.createDataFrame(ml_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- mpg: double (nullable = true)\n",
      " |-- cylinders: long (nullable = true)\n",
      " |-- displacement: double (nullable = true)\n",
      " |-- horsepower: double (nullable = true)\n",
      " |-- weight: double (nullable = true)\n",
      " |-- acceleration: double (nullable = true)\n",
      " |-- model: long (nullable = true)\n",
      " |-- origin: long (nullable = true)\n",
      " |-- car_name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RDD\n",
    "#https://sparkbyexamples.com/pyspark/pyspark-convert-dataframe-to-rdd/\n",
    "#Spark DataFrame doesn’t have methods like map(), mapPartitions() and partitionBy() \n",
    "#instead they are available on RDD hence you often need to convert DataFrame to RDD \n",
    "#and back to DataFrame.\n",
    "rdd = sdf.rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "258"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.createOrReplaceTempView('cars_info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+----------+------+------------+-----+------+--------------------+\n",
      "| mpg|cylinders|displacement|horsepower|weight|acceleration|model|origin|            car_name|\n",
      "+----+---------+------------+----------+------+------------+-----+------+--------------------+\n",
      "|18.0|        8|       307.0|     130.0|3504.0|        12.0|   70|     1|chevrolet chevell...|\n",
      "|15.0|        8|       350.0|     165.0|3693.0|        11.5|   70|     1|   buick skylark 320|\n",
      "|18.0|        8|       318.0|     150.0|3436.0|        11.0|   70|     1|  plymouth satellite|\n",
      "|16.0|        8|       304.0|     150.0|3433.0|        12.0|   70|     1|       amc rebel sst|\n",
      "|17.0|        8|       302.0|     140.0|3449.0|        10.5|   70|     1|         ford torino|\n",
      "+----+---------+------------+----------+------+------------+-----+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from cars_info limit 5\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+----------+------+------------+-----+------+--------------------+\n",
      "| mpg|cylinders|displacement|horsepower|weight|acceleration|model|origin|            car_name|\n",
      "+----+---------+------------+----------+------+------------+-----+------+--------------------+\n",
      "|18.0|        8|       307.0|     130.0|3504.0|        12.0|   70|     1|chevrolet chevell...|\n",
      "|15.0|        8|       350.0|     165.0|3693.0|        11.5|   70|     1|   buick skylark 320|\n",
      "|18.0|        8|       318.0|     150.0|3436.0|        11.0|   70|     1|  plymouth satellite|\n",
      "|16.0|        8|       304.0|     150.0|3433.0|        12.0|   70|     1|       amc rebel sst|\n",
      "|17.0|        8|       302.0|     140.0|3449.0|        10.5|   70|     1|         ford torino|\n",
      "+----+---------+------------+----------+------+------------+-----+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from cars_info where acceleration > 10 limit 5\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            car_name|\n",
      "+--------------------+\n",
      "|chevrolet chevell...|\n",
      "|   buick skylark 320|\n",
      "|  plymouth satellite|\n",
      "|       amc rebel sst|\n",
      "|         ford torino|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select car_name from cars_info where horsepower > 100 limit 5\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|Chevy_Comp_cars|\n",
      "+---------------+\n",
      "|             30|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select count(*) as Chevy_Comp_cars from cars_info where car_name like '%chev%'\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Spark ML libraries\n",
    "\n",
    "We will import and work with below SparkML functions:\n",
    "\n",
    "1.  VectorAssembler(): This is basically feature transformer that merges multiple columns into a vector column. We will use this function to create feature vectors from dataframes/raw data. These feature vectors will be used to train the ML model.\n",
    "2.  Correlation(): Calculating the correlation between two series of data is a common operation in Statistics. We will use this function to calculate correlation between feature vectors.\n",
    "3.   Normalizer(): Data normalization ensures uniformity in how your data looks, reads, and can be utilized—across all of the records in your customer database. We will use this function to normalize our features.\n",
    "4.  LinearRegression(): This function will be used to create a Linear Regression model and train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, Normalizer, StandardScaler\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting data frame columns into feature vectors\n",
    "\n",
    "Here we use the `VectorAssembler()` function to convert the dataframe columns into feature vectors.\n",
    "For our example, we use the horsepower (\"hp) and weight of the car as input features and the miles-per-gallon (\"mpg\") as target labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"horsepower\", \"weight\"],\n",
    "    outputCol=\"features\")\n",
    "\n",
    "output = assembler.transform(sdf).select('features','mpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create a test-train split of 75%-25%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = output.randomSplit([0.75, 0.25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic stats and feature engineering\n",
    "\n",
    "#### Here we determine the correlation between feature vectors and normalize the features.\n",
    "We use the correlation function to determine the different types of correlation between the 2 features - \"hp\" and \"weight\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation matrix:\n",
      "DenseMatrix([[1.        , 0.89425714],\n",
      "             [0.89425714, 1.        ]])\n"
     ]
    }
   ],
   "source": [
    "r1 = Correlation.corr(train, \"features\").head()\n",
    "print(\"Pearson correlation matrix:\\n\" + str(r1[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation matrix:\n",
      "DenseMatrix([[1.        , 0.85757102],\n",
      "             [0.85757102, 1.        ]])\n"
     ]
    }
   ],
   "source": [
    "r2 = Correlation.corr(train, \"features\", \"spearman\").head()\n",
    "print(\"Spearman correlation matrix:\\n\" + str(r2[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there is a 0.87 (or 87%) correlation between the features. That is logical as a car with higher horsepower likely has a bigger engine and thus weighs more. We can also visualize the feature vectors to see that they are indeed correlated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.scatter(ml_data[\"horsepower\"], ml_data[\"weight\"])\n",
    "plt.xlabel(\"horsepower\")\n",
    "plt.ylabel(\"weight\")\n",
    "plt.title(\"Correlation between Horsepower and Weight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization\n",
    "\n",
    "In order for better model training and convergence, let us normalize feature vectors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized using L^1 norm\n",
      "+-------------+----+-----------------------------------------+\n",
      "|features     |mpg |features_normalized                      |\n",
      "+-------------+----+-----------------------------------------+\n",
      "|[85.0,2587.0]|21.0|[0.03181137724550898,0.968188622754491]  |\n",
      "|[87.0,2672.0]|25.0|[0.031533164189923885,0.9684668358100761]|\n",
      "|[88.0,2130.0]|27.0|[0.03967538322813345,0.9603246167718665] |\n",
      "|[88.0,2130.0]|27.0|[0.03967538322813345,0.9603246167718665] |\n",
      "|[90.0,2264.0]|28.0|[0.038232795242141036,0.9617672047578589]|\n",
      "+-------------+----+-----------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "normalizer = Normalizer(inputCol=\"features\", outputCol=\"features_normalized\", p=1.0)\n",
    "train_norm = normalizer.transform(train)\n",
    "print(\"Normalized using L^1 norm\")\n",
    "train_norm.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standard Scaling\n",
    "\n",
    "This is a standard practice to scale the features such that all columns in the features have zero mean and unit variance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----+---------------------------------------+\n",
      "|features     |mpg |features_scaled                        |\n",
      "+-------------+----+---------------------------------------+\n",
      "|[85.0,2587.0]|21.0|[2.117640609331198,3.1025022036627457] |\n",
      "|[87.0,2672.0]|25.0|[2.1674674471978146,3.204439848545364] |\n",
      "|[88.0,2130.0]|27.0|[2.192380866131123,2.5544374541173744] |\n",
      "|[88.0,2130.0]|27.0|[2.192380866131123,2.5544374541173744] |\n",
      "|[90.0,2264.0]|28.0|[2.2422077039977393,2.7151391531087965]|\n",
      "+-------------+----+---------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "standard_scaler = StandardScaler(inputCol=\"features\", outputCol=\"features_scaled\")\n",
    "train_model = standard_scaler.fit(train)\n",
    "train_scaled = train_model.transform(train)\n",
    "train_scaled.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----+---------------------------------------+\n",
      "|features      |mpg |features_scaled                        |\n",
      "+--------------+----+---------------------------------------+\n",
      "|[46.0,1835.0] |26.0|[1.1460172709321779,2.2006538630541703]|\n",
      "|[90.0,2430.0] |24.0|[2.2422077039977393,2.914217377232498] |\n",
      "|[97.0,2774.0] |18.0|[2.416601636530897,3.326765022404506]  |\n",
      "|[113.0,2234.0]|26.0|[2.815216339463828,2.679161160797284]  |\n",
      "|[150.0,3433.0]|16.0|[3.737012839996232,4.117081586847393]  |\n",
      "+--------------+----+---------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_scaled = train_model.transform(test)\n",
    "test_scaled.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building and Training a Linear Regression Model\n",
    "Here we train a Linear Regression model `lrModel` on our training dataset. We train the model on the standard scaled version of features. We also print the final RMSE and R-Squared metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create and Train model\n",
    "\n",
    "We create the model using the `LinearRegression()` class and train using the `fit()` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [-2.906945600289913,-4.119118401325167]\n",
      "Intercept: 46.21946592258682\n",
      "RMSE: 4.723378\n",
      "R-squared: 0.676135\n"
     ]
    }
   ],
   "source": [
    "# Create a LR model\n",
    "lr = LinearRegression(featuresCol='features_scaled', labelCol='mpg', maxIter=100)\n",
    "\n",
    "# Fit the model\n",
    "lrModel = lr.fit(train_scaled)\n",
    "\n",
    "# Print the coefficients and intercept for linear regression\n",
    "print(\"Coefficients: %s\" % str(lrModel.coefficients))\n",
    "print(\"Intercept: %s\" % str(lrModel.intercept))\n",
    "\n",
    "# Summarize the model over the training set and print out some metrics\n",
    "trainingSummary = lrModel.summary\n",
    "#trainingSummary.residuals.show()\n",
    "print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
    "print(\"R-squared: %f\" % trainingSummary.r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a RMSE (Root mean squared error) of 4.72. This means that our model predicts the `mpg` with an average error of 4.72 units.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict on new data\n",
    "\n",
    "Once a model is trained, we can then `transform()` new unseen data (for eg. the test data) to generate predictions.\n",
    "In the below cell, notice the \"prediction\" column that contains the predicted \"mpg\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----+--------------------+------------------+\n",
      "|      features| mpg|     features_scaled|        prediction|\n",
      "+--------------+----+--------------------+------------------+\n",
      "| [46.0,1835.0]|26.0|[1.14601727093217...|33.823302236740524|\n",
      "| [90.0,2430.0]|24.0|[2.24220770399773...|27.697483678494496|\n",
      "| [97.0,2774.0]|18.0|[2.41660163653089...|25.491197406948597|\n",
      "|[113.0,2234.0]|26.0|[2.81521633946382...|27.000003133162387|\n",
      "|[150.0,3433.0]|16.0|[3.73701283999623...|18.397426364992747|\n",
      "+--------------+----+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lrModel.transform(test_scaled).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
